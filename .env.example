# ========================================
# MCP CRAWL4AI SERVER CONFIGURATION
# ========================================

# Docker Compose project name (affects volume naming)
# This determines the prefix for Docker volumes and containers
# Default: crawl4ai-mcp (if not set, uses directory name)
COMPOSE_PROJECT_NAME=crawl4ai-mcp-deimos

# The transport for the MCP server - 'http' for Docker deployment (default)
TRANSPORT=http

# Host to bind to if using sse as the transport (leave empty if using stdio)
# Set this to 0.0.0.0 if using Docker, otherwise set to localhost (if using uv)
HOST=0.0.0.0

# Port to listen on if using sse as the transport (leave empty if using stdio).
# Default port for Docker deployment
PORT=8051

# Get your Open AI API Key by following these instructions -
# https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key
# This is for the embedding model - text-embed-small-3 will be used
OPENAI_API_KEY=

# The LLM you want to use for summaries and contextual embeddings
# Generally this is a very cheap and fast LLM like gpt-4.1-nano-2025-04-14
MODEL_CHOICE=gpt-4.1-nano-2025-04-14

# ========================================
# SEARXNG INTEGRATION CONFIGURATION
# ========================================

# SearXNG URL for your search instance - configured for Docker Compose integration
# When using Docker Compose, this points to the internal SearXNG service
# For external SearXNG instances, change to: https://searx.example.com or http://host.docker.internal:8080 (for docker hosted searxng instances)
SEARXNG_URL=http://searxng:8080

# Optional: Custom user agent for SearXNG requests
SEARXNG_USER_AGENT=MCP-Crawl4AI-RAG-Server/1.0

# Optional: Default search engines to use (comma-separated list)
# Available engines depend on your SearXNG instance configuration
SEARXNG_DEFAULT_ENGINES=google,bing,duckduckgo

# Optional: Request timeout in seconds for SearXNG API calls
SEARXNG_TIMEOUT=30

# ========================================
# OPTIONAL CADDY CONFIGURATION
# ========================================

# Optional: Hostname for SearXNG Caddy reverse proxy
# Change this to your domain name for production deployment
# Default: http://localhost (matches docker-compose.yml default)
SEARXNG_HOSTNAME=http://localhost

# TLS configuration for Caddy
# Use 'internal' for self-signed certificates or provide your email for Let's Encrypt
# For production with real domain: your-email@example.com
# SEARXNG_TLS=internal

# RAG strategies - set these to "true" or "false" (default to "false")
# USE_CONTEXTUAL_EMBEDDINGS: Enhances embeddings with contextual information for better retrieval
USE_CONTEXTUAL_EMBEDDINGS=false

# Contextual Embeddings Configuration
CONTEXTUAL_EMBEDDING_MODEL=gpt-4o-mini
CONTEXTUAL_EMBEDDING_MAX_TOKENS=200
CONTEXTUAL_EMBEDDING_TEMPERATURE=0.3
CONTEXTUAL_EMBEDDING_MAX_DOC_CHARS=25000
CONTEXTUAL_EMBEDDING_MAX_WORKERS=10

# USE_HYBRID_SEARCH: Combines vector similarity search with keyword search for better results
USE_HYBRID_SEARCH=false

# USE_AGENTIC_RAG: Enables code example extraction, storage, and specialized code search functionality
USE_AGENTIC_RAG=false

# USE_RERANKING: Applies cross-encoder reranking to improve search result relevance
USE_RERANKING=false

# USE_KNOWLEDGE_GRAPH: Enables AI hallucination detection and repository parsing tools using Neo4j
# If you set this to true, you must also set the Neo4j environment variables below.
USE_KNOWLEDGE_GRAPH=false

# ========================================
# AGENTIC SEARCH CONFIGURATION
# ========================================

# Enable Agentic Search - intelligent iterative search with LLM-driven decisions
# Combines local knowledge (Qdrant), web search (SearXNG), and selective crawling
# Uses LLM evaluation to minimize costs while maximizing answer quality
AGENTIC_SEARCH_ENABLED=false

# Completeness threshold (0.0-1.0) - minimum score to consider answer complete
# Higher values = stricter quality requirements = more crawling
# Default: 0.95 (very strict - ensures comprehensive answers)
AGENTIC_SEARCH_COMPLETENESS_THRESHOLD=0.95

# Maximum search-crawl iterations before giving up
# Each iteration: local check → web search → crawl → re-evaluate
# Default: 3 (balances thoroughness with speed/cost)
AGENTIC_SEARCH_MAX_ITERATIONS=3

# Maximum URLs to crawl per iteration
# Lower values = faster iterations, higher values = more comprehensive
# Default: 3 (optimized for cost-efficiency)
AGENTIC_SEARCH_MAX_URLS_PER_ITERATION=3

# URL relevance score threshold (0.0-1.0) - minimum score to crawl a URL
# LLM ranks each URL; only URLs above this score are crawled
# Higher values = more selective crawling = lower costs
# Default: 0.7 (reasonably selective)
AGENTIC_SEARCH_URL_SCORE_THRESHOLD=0.7

# Enable search hints generation (experimental)
# Uses metadata from crawled pages to generate smarter Qdrant queries
# Requires Crawl4AI metadata extraction support
# Default: false (feature under development)
AGENTIC_SEARCH_USE_SEARCH_HINTS=false

# LLM temperature for agentic search evaluations
# Lower = more deterministic, higher = more creative
# Default: 0.3 (deterministic for completeness/ranking)
AGENTIC_SEARCH_LLM_TEMPERATURE=0.3

# Maximum results to retrieve from Qdrant per query
# Affects completeness evaluation and RAG results
# Default: 10
AGENTIC_SEARCH_MAX_QDRANT_RESULTS=10

# ========================================
# VECTOR DATABASE CONFIGURATION
# ========================================

# Choose your vector database: supabase or qdrant
# Default: qdrant (recommended for development)
VECTOR_DATABASE=qdrant

# ========================================
# SUPABASE CONFIGURATION (if VECTOR_DATABASE=supabase)
# ========================================

# Get your SUPABASE_URL from the API section of your Supabase project settings -
# https://supabase.com/dashboard/project/<your project ID>/settings/api
SUPABASE_URL=

# Get your SUPABASE_SERVICE_KEY from the API section of your Supabase project settings -
# https://supabase.com/dashboard/project/<your project ID>/settings/api
# On this page it is called the service_role secret.
SUPABASE_SERVICE_KEY=

# ========================================
# QDRANT CONFIGURATION (if VECTOR_DATABASE=qdrant)
# ========================================

# Qdrant is self-hosted in Docker, no external account needed
# Default URL when running with docker-compose
QDRANT_URL=http://qdrant:6333

# For local testing (outside Docker), use:
# QDRANT_URL=http://localhost:6333
# Start Qdrant: docker run -d --name qdrant-test qdrant/qdrant (no port mapping for security)

# Optional: API key for additional security (leave empty for local development)
QDRANT_API_KEY=

# ========================================
# NEO4J CONFIGURATION
# ========================================

# Neo4j Configuration for Knowledge Graph Tools
# These are required for the AI hallucination detection and repository parsing tools
# Neo4j is enabled by default in the development environment

# Neo4j connection URI - using Docker service name for container-to-container communication
NEO4J_URI=bolt://neo4j:7687

# Neo4j username (default: 'neo4j')
NEO4J_USERNAME=neo4j

# Neo4j password - CHANGE THIS IN PRODUCTION!
NEO4J_PASSWORD=testpassword123

# ========================================
# AUTHENTICATION CONFIGURATION
# ========================================

# MCP API Key for authentication (required for Claude Desktop)
# Generate a secure key: python -c "import secrets; print(secrets.token_urlsafe(32))"
MCP_API_KEY=

# OAuth2 Configuration (required for Claude Web Custom Connectors)
# Enable OAuth2 authentication alongside API Key authentication
USE_OAUTH2=false

# OAuth2 Issuer URL (your server's public URL)
# Example: https://your-domain.com:8051
OAUTH2_ISSUER=https://localhost:8051

# OAuth2 JWT Secret Key (CHANGE THIS IN PRODUCTION!)
# Generate: python -c "import secrets; print(secrets.token_urlsafe(32))"
OAUTH2_SECRET_KEY=change-me-in-production

# ========================================
# DEVELOPMENT-SPECIFIC SETTINGS
# ========================================

# Debug mode for verbose logging
DEBUG=false

# Log level: DEBUG, INFO, WARNING, ERROR
LOG_LEVEL=INFO

# Python optimization flags
PYTHONDONTWRITEBYTECODE=1
PYTHONUNBUFFERED=1

# ========================================
# LOAD TESTING CONFIGURATION
# ========================================

# MCP Server URL for load testing
# For local testing: http://localhost:8051
# For production testing: https://rag.melo.eu.org
MCP_SERVER_URL=http://localhost:8051

# Optional: API key for authenticated load testing
# Leave empty if server doesn't require authentication
MCP_API_KEY=

# ========================================
# TEST CONFIGURATION (Cost Protection)
# ========================================

# Enable real OpenAI API calls in tests (embeddings, cheap: ~$0.0001 per test)
# By default, OpenAI is mocked to prevent accidental costs
# ALLOW_OPENAI_TESTS=false

# Enable expensive LLM inference tests (GPT-4, etc, $$$)
# Only set to true if you understand the costs
# ALLOW_EXPENSIVE_TESTS=false