from .async_configs import BrowserConfig, CrawlerRunConfig
from .models import CrawlResult
from _typeshed import Incomplete
from typing import Any, AsyncGenerator, Callable

class Crawl4aiClientError(Exception): ...
class ConnectionError(Crawl4aiClientError): ...
class RequestError(Crawl4aiClientError): ...

class Crawl4aiDockerClient:
    base_url: Incomplete
    timeout: Incomplete
    logger: Incomplete
    def __init__(self, base_url: str = 'http://localhost:8000', timeout: float = 30.0, verify_ssl: bool = True, verbose: bool = True, log_file: str | None = None) -> None: ...
    async def authenticate(self, email: str) -> None: ...
    async def crawl(self, urls: list[str], browser_config: BrowserConfig | None = None, crawler_config: CrawlerRunConfig | None = None, hooks: dict[str, Callable] | dict[str, str] | None = None, hooks_timeout: int = 30) -> CrawlResult | list[CrawlResult] | AsyncGenerator[CrawlResult, None]: ...
    async def get_schema(self) -> dict[str, Any]: ...
    async def close(self) -> None: ...
    async def __aenter__(self) -> Crawl4aiDockerClient: ...
    async def __aexit__(self, exc_type: type | None, exc_val: Exception | None, exc_tb: Any | None) -> None: ...

async def main() -> None: ...
